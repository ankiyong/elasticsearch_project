분석기 및 매핑

```json
PUT news
{
  "settings": {
    "analysis": {
      "analyzer": {
        "nori_analyzer" : {
          "tokenizer" : "nori_tokenizer",
          "filter" : ["synonym","stop_filter"]
        }
      },
      "filter" : {
        "synonym" : {
          "type" : "synonym",
        "synonyms_path" : "analysis/synonym1.txt"
        },
         "stop_filter" : {
          "type" : "stop",
          "stopwords_path" : "analysis/stop_dic1.txt"
        }
      }
    }
  }, 
  "mappings": {
    "properties": {
      "media" : {
        "type" : "keyword"
      },
      "title" : {
        "type" : "text",
        "analyzer": "nori_analyzer"
      },
      "url" : {
        "type" : "keyword"
      },
      "text" : {
        "type" : "text",
        "analyzer": "nori_analyzer"
      }
    }
  }
}
```

우선 위와 같이 인덱스를 설정해서 테스트 해봄

title같은 경우는 검색에 지장이 크게 없어 보이는데

text 부분에서 문제가 발생했다. 

예를 들어 '중수부' 라는 단어가 있는데, nori는 중/수부 로 tokenize 하게 됨 그래서 ngram 적용해봄

```json
PUT news
{
  "settings": {
    "analysis": {
      "analyzer": {
        "nori_analyzer" : {
          "tokenizer" : "nori_tokenizer",
          "filter" : ["synonym","stop_filter"]
        },
        "ngram_analyzer" : {
          "tokenizer" : "ngram_tokenizer",
          "filter" : "stop_filter"
        }
      },
      "tokenizer": {
        "ngram_tokenizer" : {
          "type" : "ngram",
          "min_gram" : 2,
          "max_gram" : 3,
          "token_char" : "letter"
        }
      }, 
      "filter" : {
        "synonym" : {
          "type" : "synonym",
        "synonyms_path" : "analysis/synonym1.txt"
        },
         "stop_filter" : {
          "type" : "stop",
          "stopwords_path" : "analysis/stop_dic1.txt"
        }
      }
    }
  }, 
  "mappings": {
    "properties": {
      "media" : {
        "type" : "keyword"
      },
      "title" : {
        "type" : "text",
        "analyzer": "nori_analyzer"
      },
      "url" : {
        "type" : "keyword"
      },
      "text" : {
        "type" : "text",
        "analyzer": "ngram_analyzer"
      }
    }
  }
}
```

ngram을 적용하니 검색이 더 잘 됨

근데 이게 속도에 어떤 영향을 주는지 확인해 봐야함

그리고 검색 기능 향상을 위해 search analyzer를 적용해 보려고 시도함

```json
 "text" : {
        "type" : "text",
        "analyzer": "ngram_analyzer",
     	"search_analyzer" : "standard"
 }
본문을 ngram으로 tokenize 해서 token 형태가 너무 달라서 검색이 잘 안됨
```

```json
 "text" : {
        "type" : "text",
        "analyzer": "ngram_analyzer",
     	"search_analyzer" : "edge_ngram_analyzer"
 }
역시나 token 모양이 너무 달라서 검색이 잘 안됨
```

그런데 검색하다 보니 뭔가 이상함

'윤석열' 검색했더니 '윤석' 기자의 글이 검색 됨

ngram 과 search_analyzer가 문제였음

그래서 ngram의 설정값을 변경하고 search_analyzer 를 standard로 바꿈

왜냐면 검색어와 일치하는 단어를 검색해야 하기 때문임

```json
PUT news
{
  "settings": {
    "index.max_ngram_diff" : 10,
	...
      "tokenizer": {
        "ngram_tokenizer" : {
          "type" : "ngram",
          "min_gram" : 1,
          "max_gram" : 10,
          "token_char" : "letter"
	...
      "text" : {
        "type" : "text",
        "analyzer": "ngram_analyzer",
        "search_analyzer": "standard"
      }
    }
  }
}
이렇게 하면 검색어를 그대로 tokenize 하고 
text를 첫 글자부터 모든 글자를 출력하는 단계까지 다 하기 때문에 검색이 용이함
```



검색창 한칸을 사용해서 모든 검색어를 검색할 것이기 때문에 search template에서 should를 사용했다

```json
PUT _scripts/test_template
{
  "script" : {
    "lang": "mustache",
    "source": {
      "query" : {
        "bool" : {
          "should" : [
            {
              "query_string" : {
                "default_field" : "title",
                "query" : "{{keyword}}"
                }
              },
            {
              "query_string" : {
                "default_field" : "text",
                "query" : "{{keyword}}"
                }
              },
            {
              "query_string" : {
                "default_field" : "media",
                "query" : "{{keyword}}"
              }
            }
          ]
        }
      }
    }
  }
}
```

